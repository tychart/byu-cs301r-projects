# Before running this script:
# pip install gradio openai docker

import argparse
import asyncio
import io
import json
import sys
from pathlib import Path
from typing import List, Any, Dict

import gradio as gr
from openai import AsyncOpenAI
from openai.types.shared_params.reasoning import Reasoning
from openai.types.responses import FunctionToolParam



from tools import ToolBox
from usage import print_usage, format_usage_markdown

from dotenv import load_dotenv
load_dotenv()

our_tools = ToolBox()

# # if you want to try the superbowl "database" use this
# from superbowldb import get_superbowl_info
# our_tools.tools(get_superbowl_info)
#
# # if you want to try executing code in the container from the docker directory use this
from codebot import execute_code
our_tools.tool(execute_code)

def _exec_python(code) -> tuple[str, str]:
    out_buffer = io.StringIO()
    err_buffer = io.StringIO()

    original_stdout = sys.stdout
    original_stderr = sys.stderr
    try:
        sys.stdout = out_buffer
        sys.stderr = err_buffer
        try:
            exec(code, {})  # isolated global namespace
        except:
            import traceback as tb
            tb.format_exc()
    finally:
        sys.stdout = original_stdout
        sys.stderr = original_stderr
    return out_buffer.getvalue(), err_buffer.getvalue()


# @our_tools.tool
def exec_python(code: str) -> tuple[str, str]:
    """Execute the provided python code. STDOUT and STDERR are returned."""
    print()
    print(' Agent Code '.center(40, '-'))
    print(code)
    print('-' * 40)
    response = input('Allow? [y/N] ')

    if response.lower() == 'y':
        return _exec_python(code)

    print()
    return ('This code was not approved by the user. Discuss with them an alternative.', 'Error: code execution failed')


class ChatAgent:
    def __init__(self, model: str, prompt: str, show_reasoning: bool, reasoning_effort: str | None):
        self._ai = AsyncOpenAI()
        self.model = model
        self.show_reasoning = show_reasoning
        self.reasoning: Reasoning = {}
        if show_reasoning:
            self.reasoning['summary'] = 'auto'
        if 'gpt-5' in self.model and reasoning_effort:
            match reasoning_effort:
                case "none" | "minimal" | "low" | "medium" | "high" | "xhigh":
                    self.reasoning["effort"] = reasoning_effort
                case _:
                    raise ValueError(f"Invalid reasoning effort: {reasoning_effort}")


        self.usage = []
        self.usage_markdown = format_usage_markdown(self.model, [])

        self._history = []
        self._prompt = prompt
        if prompt:
            self._history.append({'role': 'system', 'content': prompt})

        self.tools: List[FunctionToolParam] = list(our_tools.tools)

        searchtool: FunctionToolParam = {"type": "web_search"}         # pyright: ignore[reportAssignmentType]
        builtin_tools: List[FunctionToolParam] = [searchtool]        
        self.tools += builtin_tools


    async def get_response(self, user_message: str):
        self._history.append({'role': 'user', 'content': user_message})

        while True:
            response = await self._ai.responses.create(
                input=self._history,
                model=self.model,
                reasoning=self.reasoning,
                tools= self.tools
            )

            self.usage.append(response.usage)
            self.usage_markdown = format_usage_markdown(self.model, self.usage)
            self._history.extend(
                response.output
            )

            for item in response.output:
                if item.type == 'reasoning':
                    for chunk in item.summary:
                        yield 'reasoning', chunk.text

                elif item.type == 'function_call':
                    yield 'reasoning', f'{item.name}({item.arguments})'

                    func = our_tools.get_tool_function(item.name)
                    args = json.loads(item.arguments)
                    result = func(**args) # pyright: ignore[reportOptionalCall]
                    self._history.append({
                        'type': 'function_call_output',
                        'call_id': item.call_id,
                        'output': str(result)
                    })
                    yield 'reasoning', str(result)

                elif item.type == 'message':

                    print('')
                    print("==================")
                    print("Output to user:")
                    # print(f"item.content: {item.content}")

                    for chunk in item.content:
                        if (chunk.type == 'output_text'):
                            yield 'output', chunk.text
                    print('')
                    print("==================")
                    return

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        print_usage(self.model, self.usage)


async def _main_console(agent_args):
    with ChatAgent(**agent_args) as agent:
        while True:
            message = input('User: ')
            if not message:
                break

            reasoning_complete = True
            if agent.show_reasoning:
                print(' Reasoning '.center(30, '-'))
                reasoning_complete = False

            last_type = ''
            async for text_type, text in agent.get_response(message):
                if text_type == 'output' and not reasoning_complete:
                    print()
                    print('-' * 30)
                    print()
                    print('Agent: ')
                    reasoning_complete = True

                if last_type != text_type:
                    print(f'\n{text_type}: ', end='', flush=True)       # emit a newline between types
                    last_type = text_type

                print(text, end='', flush=True)
            print()
            print()


def _main_gradio(agent_args):
    # Constrain width with CSS and center
    css = """
    /* limit overall Gradio app width and center it */
    .gradio-container, .gradio-app, .gradio-root {
      width: 120ch;
      max-width: 120ch !important;
      margin-left: auto !important;
      margin-right: auto !important;
      box-sizing: border-box !important;
    }
    
    #reasoning-md {
        max-height: 300px;
        overflow-y: auto;
    }
    """

    reasoning_view = gr.Markdown('', elem_id='reasoning-md')
    usage_view = gr.Markdown('')

    with gr.Blocks(css=css, theme=gr.themes.Monochrome()) as demo: # pyright: ignore[reportPrivateImportUsage]
        agent = gr.State()

        async def get_response(message, chat_view_history, agent):
            output = ""
            reasoning = ""

            async for text_type, text in agent.get_response(message):
                if text_type == 'reasoning':
                    reasoning += text
                elif text_type == 'output':
                    output += text
                else:
                    raise NotImplementedError(text_type)

                yield output, reasoning, agent.usage_markdown, agent

            yield output, reasoning, agent.usage_markdown, agent

        with gr.Row():
            with gr.Column(scale=5):
                bot = gr.Chatbot(
                    label=' ',
                    height=600,
                    resizable=True,
                )
                chat = gr.ChatInterface(
                    chatbot=bot,
                    fn=get_response,
                    additional_inputs=[agent],
                    additional_outputs=[reasoning_view, usage_view, agent]
                )

            with gr.Column(scale=1):
                reasoning_view.render()
                usage_view.render()

        demo.load(fn=lambda: ChatAgent(**agent_args), outputs=[agent])

    demo.launch()


def main(prompt_path: Path, model: str, show_reasoning, reasoning_effort: str | None, use_web: bool):
    agent_args = dict(
        model=model,
        prompt=prompt_path.read_text() if prompt_path else '',
        show_reasoning=show_reasoning,
        reasoning_effort=reasoning_effort

    )

    if use_web:
        _main_gradio(agent_args)
    else:
        asyncio.run(_main_console(agent_args))


# Launch app
if __name__ == "__main__":
    parser = argparse.ArgumentParser('ChatBot')
    parser.add_argument('prompt_file', nargs='?', type=Path, default=None)
    parser.add_argument('--web', action='store_true')
    parser.add_argument('--model', default='gpt-5-nano')
    parser.add_argument('--show-reasoning', action='store_true')
    parser.add_argument('--reasoning-effort', default='low')
    args = parser.parse_args()
    main(args.prompt_file, args.model, args.show_reasoning, args.reasoning_effort, args.web)
